{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup magic autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from pathlib import Path\n",
    "from IPython.display import Image, display, Markdown\n",
    "from langchain_core.runnables.graph import CurveStyle, MermaidDrawMethod, NodeStyles\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "# In case of debugging, set the level to logging.DEBUG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ensure that you have already configured your environment variable following the instructions in the [README](../README.md)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "assert os.getenv('LLM_DSL_CONFIG_PATH') is not None, \"Please set the LLM_DSL_CONFIG_PATH environment variable to the path of the config file\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. First glance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dsl_gen.core.flows import build_rag_flow\n",
    "\n",
    "flow = build_rag_flow()\n",
    "display(\n",
    "    Image(\n",
    "        flow.get_graph().draw_mermaid_png(\n",
    "            draw_method=MermaidDrawMethod.API,\n",
    "        )\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dsl_gen import CFG\n",
    "\n",
    "CFG.MODEL_CFG.active_model = \"openai\"\n",
    "challenge_path = Path(CFG.PATH_CFG.CHALLENGES_PATH) / \"c008.json\" \n",
    "\n",
    "flow = build_rag_flow()\n",
    "\n",
    "result = flow.invoke({\"challenge_path\": str(challenge_path)}) \n",
    "\n",
    "display(Markdown(f\"```envision\\n{result['completion']}```\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or you can simply pass a string as the question for the workflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = 'Define a text literal called greetings with value \"Hello\" and display greetings on the dashboard as a label.'\n",
    "\n",
    "result = flow.invoke({\"query\": query})\n",
    "\n",
    "display(Markdown(f\"```envision\\n{result['completion']}```\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Components"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VectorDB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uncomment the following line to build vectorstore manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from dsl_gen.core.vector_store import _build_vectorstore\n",
    "# store = _build_vectorstore()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize a question\n",
    "\n",
    "Before building vectorstore, we can visualize a question to understand the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Markdown\n",
    "\n",
    "\n",
    "display(Markdown(query))\n",
    "answer = '```envision\\ngreetings = \"Hello\" // define the text literal\\nshow label greetings // show the text literal as a label. There should be no \\'with\\' !\\n```'\n",
    "display(Markdown(answer))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build vectorstore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dsl_gen.core.vector_store import get_vectorstore\n",
    "from dsl_gen.config import CFG\n",
    "\n",
    "# It is normal that you see INFO - Failed to load GPU Faiss\n",
    "# Since we are using CPU Faiss\n",
    "vectorstore = get_vectorstore()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:green;\"><b>It is normal that you see the message</b></span> `Failed to load GPU Faiss` <span style=\"color:green;\"><b>since we are using</b></span> `Faiss-CPU`.\n",
    "\n",
    "Let's see how to retrieve docs by their indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Markdown\n",
    "doc_ids = list(vectorstore.index_to_docstore_id.values())[:5]\n",
    "for doc_id in doc_ids:\n",
    "    document = vectorstore.docstore.search(doc_id)\n",
    "    display(Markdown(document.page_content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_ids = list(vectorstore.index_to_docstore_id.values())[50:53]\n",
    "\n",
    "display(Markdown('### Displaying documents 50, 51, 52'))\n",
    "\n",
    "for doc_id in doc_ids:\n",
    "    document = vectorstore.docstore.search(doc_id)\n",
    "    \n",
    "    display(Markdown(document.page_content))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Similarity search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorstore = get_vectorstore()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query=\"Define a text literal called greetings with value \\\"Hello\\\" and display greetings on the dashboard as a label.\"\n",
    "documents = vectorstore.similarity_search(k = 3, query=query)\n",
    "document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, doc in enumerate(documents):\n",
    "    display(Markdown(f\"### Document {idx} \\n {doc.page_content}\"))\n",
    "display(Markdown('---'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try queries with a few questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dsl_gen.core.vector_store import get_vectorstore\n",
    "from dsl_gen.config import CFG\n",
    "from pathlib import Path\n",
    "import json\n",
    "\n",
    "vectorstore = get_vectorstore()\n",
    "\n",
    "file_path = Path(CFG.PATH_CFG.CHALLENGES_PATH) / \"c001.json\"\n",
    "\n",
    "with open(file_path, 'r') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "question = data['question']\n",
    "\n",
    "print(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = vectorstore.similarity_search(k = 20, query=question)\n",
    "document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, doc in enumerate(documents):\n",
    "    print(f\"Document {idx}\")\n",
    "    print(doc.page_content)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test RAG flow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "from langchain_core.runnables.graph import CurveStyle, MermaidDrawMethod, NodeStyles\n",
    "\n",
    "from dsl_gen.core.flows import build_rag_flow\n",
    "\n",
    "flow = build_rag_flow()\n",
    "display(\n",
    "    Image(\n",
    "        flow.get_graph().draw_mermaid_png(\n",
    "            draw_method=MermaidDrawMethod.API,\n",
    "        )\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(flow.get_graph().draw_mermaid())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Invoke workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dsl_gen import CFG\n",
    "from pathlib import Path\n",
    "from dsl_gen.core.flows import build_rag_flow\n",
    "import logging\n",
    "from IPython.display import Image, display\n",
    "from langchain_core.runnables.graph import CurveStyle, MermaidDrawMethod, NodeStyles\n",
    "\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "# Reset the active model to openai to boost inference speed\n",
    "CFG.MODEL_CFG.active_model = \"openai\"\n",
    "\n",
    "challenge_path = Path(CFG.PATH_CFG.CHALLENGES_PATH) / \"c001.json\" \n",
    "\n",
    "flow = build_rag_flow()\n",
    "\n",
    "# It is normal that you see 'INFO - Failed to load GPU Faiss'\n",
    "# since we are using CPU\n",
    "result = flow.invoke({\"challenge_path\": str(challenge_path)}) \n",
    "\n",
    "print(result[\"completion\"]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Appendix: VectorStore\n",
    "\n",
    "Below is a detailed explanation of VectorStore content display and similarity search filters:\n",
    "\n",
    "---\n",
    "\n",
    "## How to View Chunk Content in VectorStore\n",
    "\n",
    "### Method 1: Directly Accessing the Underlying Storage (Using FAISS as an Example)\n",
    "\n",
    "```python\n",
    "# Assuming an initialized vectorstore object\n",
    "\n",
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "def show_all_chunks(vectorstore: FAISS) -> list:\n",
    "    \"\"\"Displays all stored chunks and their metadata\"\"\"\n",
    "    chunks = []\n",
    "    # Iterate through all document IDs\n",
    "    for doc_id in vectorstore.index_to_docstore_id.values():\n",
    "        document = vectorstore.docstore.search(doc_id)\n",
    "        chunks.append({\n",
    "            \"id\": doc_id,\n",
    "            \"content\": document.page_content,\n",
    "            \"metadata\": document.metadata\n",
    "        })\n",
    "    return chunks\n",
    "\n",
    "# Example usage\n",
    "for chunk in show_all_chunks(vectorstore):\n",
    "    print(f\"[ID: {chunk['id']}]\")\n",
    "    print(f\"Metadata: {chunk['metadata']}\")\n",
    "    print(f\"Content: {chunk['content'][:50]}...\\n\")\n",
    "\n",
    "# Sample Output:\n",
    "# [ID: 89a3b2f1]\n",
    "# Metadata: {'source': 'manual.pdf', 'page': 23}\n",
    "# Content: Envision language supports time series analysis using window functions...\n",
    "```\n",
    "\n",
    "### Method 2: Retrieve All Chunks via Search (Temporary Approach)\n",
    "```python\n",
    "# Retrieve all documents by searching an empty string (Use with caution)\n",
    "all_docs = vectorstore.similarity_search(query=\"\", k=1000)  # Set k to a sufficiently large number\n",
    "for i, doc in enumerate(all_docs):\n",
    "    print(f\"Chunk {i+1}: {doc.page_content[:80]}...\")\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## **Understanding the `similarity_search` Filter Parameter**\n",
    "\n",
    "### Purpose\n",
    "- **Metadata Filtering**: Restrict searches to documents that meet specific criteria.\n",
    "- **Performance Optimization**: Reduce the number of candidate documents that need to be compared.\n",
    "- **Business Adaptability**: Dynamically adjust the search scope based on use cases.\n",
    "\n",
    "### Filtering Syntax Examples\n",
    "```python\n",
    "# Basic filtering (Equality)\n",
    "vectorstore.similarity_search(\n",
    "    \"Time Series Forecasting\",\n",
    "    filter={\"source\": \"finance_docs\"},  # Search only financial documents\n",
    "    k=3\n",
    ")\n",
    "\n",
    "# Comparison Operators\n",
    "vectorstore.similarity_search(\n",
    "    \"Data Cleaning\",\n",
    "    filter={\n",
    "        \"page\": {\"$gte\": 50},          # Page number >= 50\n",
    "        \"version\": {\"$ne\": \"draft\"}    # Exclude draft versions\n",
    "    }\n",
    ")\n",
    "\n",
    "# Multiple Conditions\n",
    "vectorstore.similarity_search(\n",
    "    \"Machine Learning\",\n",
    "    filter={\n",
    "        \"$and\": [\n",
    "            {\"category\": \"AI\"},\n",
    "            {\"security_level\": {\"$lte\": 2}}\n",
    "        ]\n",
    "    }\n",
    ")\n",
    "\n",
    "# Array Containment\n",
    "vectorstore.similarity_search(\n",
    "    \"Distributed Computing\", \n",
    "    filter={\n",
    "        \"tags\": {\"$in\": [\"spark\", \"hadoop\"]}  # Includes any specified tags\n",
    "    }\n",
    ")\n",
    "```\n",
    "\n",
    "### Supported Operators\n",
    "| Operator | Description             | Example                          |\n",
    "|----------|-------------------------|----------------------------------|\n",
    "| `$eq`    | Equals (default)         | `{\"author\": \"John\"}`            |\n",
    "| `$ne`    | Not equals               | `{\"status\": {\"$ne\": \"draft\"}}`  |\n",
    "| `$gt`    | Greater than             | `{\"views\": {\"$gt\": 1000}}`      |\n",
    "| `$gte`   | Greater than or equal to | `{\"year\": {\"$gte\": 2020}}`      |\n",
    "| `$lt`    | Less than                | `{\"priority\": {\"$lt\": 5}}`      |\n",
    "| `$lte`   | Less than or equal to    | `{\"rating\": {\"$lte\": 4.5}}`     |\n",
    "| `$in`    | Contained in array       | `{\"tags\": {\"$in\": [\"AI\"]}}`     |\n",
    "| `$nin`   | Not contained in array   | `{\"lang\": {\"$nin\": [\"zh\"]}}`    |\n",
    "| `$and`   | Logical AND              | See combined example above      |\n",
    "| `$or`    | Logical OR               | `{\"$or\": [cond1, cond2]}`       |\n",
    "\n",
    "---\n",
    "\n",
    "## **Best Practices and Practical Advice**\n",
    "\n",
    "### 1. **Metadata Design Tips**\n",
    "- Inject structured metadata when splitting documents.\n",
    "```python\n",
    "from langchain.docstore.document import Document\n",
    "\n",
    "Document(\n",
    "    page_content=chunk_text,\n",
    "    metadata={\n",
    "        \"source\": \"user_manual_v3.pdf\",\n",
    "        \"section\": \"API Reference\",\n",
    "        \"last_updated\": \"2024-03-15\"\n",
    "    }\n",
    ")\n",
    "```\n",
    "\n",
    "### 2. **Efficient Filtering Strategies**\n",
    "```python\n",
    "# Predefined common filters\n",
    "FILTERS = {\n",
    "    \"technical_docs\": {\"doc_type\": \"technical\"},\n",
    "    \"recent_updates\": {\"last_updated\": {\"$gte\": \"2024-01-01\"}},\n",
    "    \"high_priority\": {\"priority\": {\"$gte\": 8}}\n",
    "}\n",
    "\n",
    "# Dynamically build filters\n",
    "def build_filter(include_filters: list[str]):\n",
    "    return {\"$and\": [FILTERS[f] for f in include_filters]}\n",
    "```\n",
    "\n",
    "### 3. **Debugging and Metadata Analysis**\n",
    "```python\n",
    "# Display metadata field distributions\n",
    "from collections import defaultdict\n",
    "\n",
    "def analyze_metadata(vectorstore):\n",
    "    field_stats = defaultdict(set)\n",
    "    for doc_id in vectorstore.index_to_docstore_id.values():\n",
    "        doc = vectorstore.docstore.search(doc_id)\n",
    "        for k, v in doc.metadata.items():\n",
    "            field_stats[k].add(str(v))  # Convert to string to avoid type issues\n",
    "  \n",
    "    for field, values in field_stats.items():\n",
    "        print(f\"Field '{field}':\")\n",
    "        print(f\"  Unique values ({len(values)}): {', '.join(list(values)[:3])}...\")\n",
    "\n",
    "# Sample Output:\n",
    "# Field 'source': \n",
    "#   Unique values (4): manual_v2.pdf, blog_post.md, api_spec.json...\n",
    "```\n",
    "\n",
    "By effectively utilizing metadata filtering and content inspection methods, you can significantly enhance the **controllability** and **interpretability** of a Retrieval-Augmented Generation (RAG) system."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mvd-3d",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
